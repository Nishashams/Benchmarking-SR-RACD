{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C6m7Lj9m0h5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import random\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import Model\n",
        "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from numpy.random import random_integers\n",
        "\n",
        "from skimage.metrics import mean_squared_error\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from skimage.metrics import normalized_root_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "BxUxNwHSxjlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "urv0TepZqpdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d7bd7c-1730-4c39-cd75-43f0d4c1c1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator**"
      ],
      "metadata": {
        "id": "ZrbHuiVbuRdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define blocks to build the generator\n",
        "def res_block(ip):\n",
        "  res_model = Conv2D(64, (3,3), padding = \"same\")(ip)//64\n",
        "  res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "\n",
        "  res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)//64\n",
        "\n",
        "  return add([ip,res_model])\n",
        "\n",
        "def upscale_block(ip):\n",
        "  up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "  up_model = UpSampling2D( size = 2 )(up_model)\n",
        "  up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "\n",
        "  return up_model"
      ],
      "metadata": {
        "id": "V_KnKDCRuOZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descriminator**"
      ],
      "metadata": {
        "id": "ttasGVhMunyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriminator block that wiL be used to construct the discriminator\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "  disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "\n",
        "  disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "  return disc_model"
      ],
      "metadata": {
        "id": "R-fL-CM7um2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator Model**"
      ],
      "metadata": {
        "id": "nTM8yhBgu7nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generator model\n",
        "num_res_block = 16\n",
        "\n",
        "def create_generator_model(gen_ip, num_res_block):\n",
        "    # Initial convolutional layer\n",
        "    layers = Conv2D(64, (9, 9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1, 2])(layers)\n",
        "\n",
        "    # Store a copy of the initial layer for later addition\n",
        "    temp = layers\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "\n",
        "    # Final residual block and addition with the initial layer\n",
        "    layers = Conv2D(64, (3, 3), padding=\"same\")(layers)\n",
        "    layers = add([layers, temp])\n",
        "\n",
        "    # Upscaling blocks\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    # Output convolutional layer\n",
        "    output_layer = Conv2D(3, (9, 9), padding=\"same\")(layers)\n",
        "\n",
        "    # Define and return the generator model\n",
        "    return Model(inputs=gen_ip, outputs=output_layer)"
      ],
      "metadata": {
        "id": "6DPBOjiav5rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descriminator Model**"
      ],
      "metadata": {
        "id": "D8N1FscDuyw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#descriminartor, as described in the original paper\n",
        "def create_disc(disc_ip):\n",
        "  df = 64\n",
        "  d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "  d2 = discriminator_block(d1, df, strides=2)\n",
        "  d3 = discriminator_block(d2, df*2)\n",
        "  d4 = discriminator_block(d3, df*2, strides=2)\n",
        "  ds = discriminator_block(d4, df*4)\n",
        "  d6 = discriminator_block(ds, df*4, strides=2)\n",
        "  d7 = discriminator_block(d6, df*8)\n",
        "  d8 = discriminator_block(d7, df*8, strides=2)\n",
        "  d8_5 = Flatten()(d8)\n",
        "  d9 = Dense(df*16)(d8_5)\n",
        "  d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "  validity = Dense(1, activation='sigmoid')(d10)\n",
        "  return Model( disc_ip, validity)"
      ],
      "metadata": {
        "id": "Rqwy9SIiux2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG19**"
      ],
      "metadata": {
        "id": "nAhHeTO1vI8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg(hr_shape):\n",
        "  vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "  return Model (inputs=vgg.inputs, outputs=vgg.layers[10].output)\n"
      ],
      "metadata": {
        "id": "3Ff0HAZuvH-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combined model**"
      ],
      "metadata": {
        "id": "HlhTMeayvRYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combined model\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "  gen_img = gen_model(lr_ip)\n",
        "  gen_features = vgg(gen_img)\n",
        "  disc_model.trainable = False\n",
        "  validity = disc_model(gen_img)\n",
        "  return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
      ],
      "metadata": {
        "id": "vTM66VOtD1Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=5900\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/dataset/Benchmark dataset/FINALCCTV\"\n",
        "\n",
        "lr_list = os.listdir(train_dir+\"/lrcctv\")[:n]\n",
        "lr_images = []\n",
        "for img in lr_list:\n",
        "  img_lr = cv2.imread(train_dir+\"/lrcctv/\" + img)\n",
        "  img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
        "  lr_images.append(img_lr)\n",
        "\n",
        "hr_list = os.listdir(train_dir+\"/hrcctv\")[:n]\n",
        "hr_images = []\n",
        "for img in hr_list:\n",
        "  img_hr = cv2.imread(train_dir+\"/hrcctv/\" + img)\n",
        "  img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
        "  hr_images.append (img_hr)\n",
        "\n",
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)\n",
        "\n",
        "print(lr_images.shape)\n",
        "print(hr_images.shape)"
      ],
      "metadata": {
        "id": "JWHlOcTaEgyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check, view few mages\n",
        "\n",
        "image_number = random.randint(0, len(lr_images)-1)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(lr_images[image_number], (32, 32, 3)))\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(hr_images[image_number], (128, 128, 3)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7SGR9cJmI5Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_images = lr_images / 255.\n",
        "hr_images = hr_images / 255.\n",
        "#Split to train and test\n",
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, test_size=0.33, random_state=1)"
      ],
      "metadata": {
        "id": "5t46UPquSTnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
        "\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n",
        "\n",
        "generator = create_generator_model(lr_ip, num_res_block = 16)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "mG6Ompu6JE5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "FotXCNp0VzIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = build_vgg((128,128,3))\n",
        "print(vgg.summary())\n",
        "vgg.trainable = False\n"
      ],
      "metadata": {
        "id": "D_Hq2zZZV1d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install image-quality"
      ],
      "metadata": {
        "id": "VED1xV3GivKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
        "gan_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=[1e-3, 1],optimizer='adam')\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "wZOIc1W2V5Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(gan_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "ZMBcDcfZe9dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "  start_idx = it * batch_size\n",
        "  end_idx = start_idx + batch_size\n",
        "  train_hr_batches.append (hr_train[start_idx:end_idx])\n",
        "  train_lr_batches.append (lr_train[start_idx:end_idx])\n"
      ],
      "metadata": {
        "id": "1vyouZsvcF4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot loss"
      ],
      "metadata": {
        "id": "YuXW2bFwInLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLosses(d_loss, g_loss, e):\n",
        "        fig, ax1 = plt.subplots(figsize=(5, 5))\n",
        "        color = 'tab:blue'\n",
        "        ax1.plot(d_loss, color=color, label='Dis loss')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Dis loss', color=color)\n",
        "        ax1.tick_params('y', color=color)\n",
        "        color = 'tab:green'\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(g_loss, color=color, label='Gen loss')\n",
        "        ax2.set_ylabel('Gen loss', color=color)\n",
        "        ax2.tick_params('y', color=color)\n",
        "        plt.title('Discriminator & Generator Losses')\n",
        "        plt.savefig('Losses_%d.png' % e)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "77JXxkf9Il-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "def calculate_loss(model, data, labels):\n",
        "    return model.train_on_batch(data, labels)\n",
        "\n",
        "def train_discriminator(discriminator, generator, lr_imgs, hr_imgs, fake_label, real_label):\n",
        "    fake_imgs = generator.predict_on_batch(lr_imgs)\n",
        "\n",
        "    discriminator.trainable = True\n",
        "    d_loss_gen = calculate_loss(discriminator, fake_imgs, fake_label)\n",
        "    d_loss_real = calculate_loss(discriminator, hr_imgs, real_label)\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
        "    return d_loss\n",
        "\n",
        "def train_generator(gan_model, lr_imgs, hr_imgs, real_label, vgg):\n",
        "    discriminator.trainable = False\n",
        "    image_features = vgg.predict(hr_imgs)\n",
        "    g_loss, _, _ = calculate_loss(gan_model, [lr_imgs, hr_imgs], [real_label, image_features])\n",
        "    return g_loss\n",
        "\n",
        "for e in range(epochs):\n",
        "    fake_label = np.zeros((batch_size, 1))\n",
        "    real_label = np.ones((batch_size, 1))\n",
        "\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    for lr_imgs, hr_imgs in tqdm(zip(train_lr_batches, train_hr_batches), total=len(train_hr_batches)):\n",
        "        d_loss = train_discriminator(discriminator, generator, lr_imgs, hr_imgs, fake_label, real_label)\n",
        "        g_loss = train_generator(gan_model, lr_imgs, hr_imgs, real_label, vgg)\n",
        "\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "    g_loss_avg = np.mean(g_losses, axis=0)\n",
        "    d_loss_avg = np.mean(d_losses, axis=0)\n",
        "\n",
        "    print(f\"Epoch: {e + 1}, Generator Loss: {g_loss_avg}, Discriminator Loss: {d_loss_avg}\")\n",
        "\n",
        "    if (e + 1) % 10 == 0:\n",
        "        discriminator.save_weights(f\"disc_e_{e+1}.h5\")\n",
        "        generator.save_weights(f\"gen_e_{e+1}.h5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IJ9FZSJ0rytZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(g_losses,label='g_losses')\n",
        "plt.plot(d_losses,label='d_losses')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "G9LrHpVMskc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example data for g_losses and d_losses (replace with your actual data)\n",
        "g_losses = [0.1, 0.2, 0.15, 0.25, 0.18]\n",
        "d_losses = [0.05, 0.08, 0.12, 0.1, 0.15]\n",
        "\n",
        "# Create a DataFrame\n",
        "loss_data = {\n",
        "    'Epoch': range(1, len(g_losses) + 1),\n",
        "    'g_losses': g_losses,\n",
        "    'd_losses': d_losses\n",
        "}\n",
        "df = pd.DataFrame(loss_data)\n",
        "\n",
        "# Apply formatting and colors\n",
        "styled_df = df.style.format({\n",
        "    'g_losses': '{:.2f}',\n",
        "    'd_losses': '{:.2f}'\n",
        "}).set_properties(**{'text-align': 'center'})\n",
        "\n",
        "styled_df = styled_df.set_table_styles([{\n",
        "    'selector': 'th',\n",
        "    'props': [\n",
        "        ('background-color', 'lightgrey'),\n",
        "        ('text-align', 'center')\n",
        "    ]\n",
        "}, {\n",
        "    'selector': 'tr:hover',\n",
        "    'props': [('background-color', 'yellow')]\n",
        "}])\n",
        "\n",
        "# Display the formatted table\n",
        "styled_df\n"
      ],
      "metadata": {
        "id": "qeJRTB3fBZ_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp=str(e+1)\n",
        "print(temp)\n",
        "!ls gen_e_10.h5"
      ],
      "metadata": {
        "id": "fHg1BE5XVGhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generator = load_model('gen_e_10.h5', compile=False)\n",
        "\n",
        "[X1, X2] = [lr_test, hr_test]\n",
        "\n",
        "# Use np.random.randint instead of random_integers\n",
        "ix = np.random.randint(0, len(X1), 1)\n",
        "src_image, tar_image = X1[ix], X2[ix]\n",
        "\n",
        "# Use generator.predict_on_batch for consistency\n",
        "gen_image = generator.predict_on_batch(src_image)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Plot LR Image\n",
        "plt.subplot(231)\n",
        "plt.title('LR Image')\n",
        "plt.imshow(src_image[0])\n",
        "\n",
        "# Plot Superresolution Image\n",
        "plt.subplot(232)\n",
        "plt.title('Superresolution')\n",
        "plt.imshow(gen_image[0])\n",
        "\n",
        "# Plot Original HR Image\n",
        "plt.subplot(233)\n",
        "plt.title('Orig. HR image')\n",
        "plt.imshow(tar_image[0])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tclMg0K1t4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "yKXOW-UgxWQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_img=mean_squared_error(gen_image[0,:,:,:],tar_image[0,:,:,:])\n",
        "print(\"MSE : \",mse_img)\n",
        "\n",
        "ssim_img=ssim(gen_image[0,:,:,:],tar_image[0,:,:,:],multichannel=True)\n",
        "print(\"SSIM : \",ssim_img)\n",
        "\n",
        "rmse_img=normalized_root_mse(gen_image[0,:,:,:],tar_image[0,:,:,:])\n",
        "print(\"NRMSE : \",rmse_img)"
      ],
      "metadata": {
        "id": "a063hkEAyX3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "\n",
        "# Assuming your images are in the range [0, 255] for 8-bit images\n",
        "data_range = 255\n",
        "psnr_img = peak_signal_noise_ratio(gen_image[0,:,:,:], tar_image[0,:,:,:], data_range=data_range)\n",
        "print(\"PSNR : \", psnr_img)"
      ],
      "metadata": {
        "id": "iaHVapaog6ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "o3p-5SyR0_dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "L0-CFeTuExRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['MSE','SSIM','NRMSE','PSNR']\n",
        "#arr=[[mse_img,ssim_img,rmse_img,score]]\n",
        "arr=[[mse_img,ssim_img,rmse_img,psnr_img]]\n",
        "print (tabulate(arr, headers=[\"MSE\",\"SSIM\",\"NRMSE\",\"PSNR\"],tablefmt=\"fancy_grid\"))\n"
      ],
      "metadata": {
        "id": "e4QB8LVNxk3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}